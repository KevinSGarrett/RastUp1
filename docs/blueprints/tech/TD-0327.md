<!-- id: TD-0327 | source: ProjectPlans\TechnicalDevelopmentPlan.odt | range: 1177200-1181200 -->

e writes** (*global_readonly=true*).
5609. **Restore new cluster to TS**:

*aws rds restore-db-cluster-to-point-in-time \\*\
*\--region \$PRIMARY \\*\
*\--db-cluster-identifier \$NEW_CLUSTER_ID \\*\
*\--source-db-cluster-identifier \$AURORA_CLUSTER_ID \\*\
*\--restore-to-time \"\$RESTORE_TS\" \\*\
*\--use-latest-restorable-time false \\*\
*\--engine aurora-postgresql*\
*aws rds create-db-instance \\*\
*\--region \$PRIMARY \\*\
*\--db-instance-identifier \${NEW_CLUSTER_ID}-writer \\*\
*\--db-cluster-identifier \$NEW_CLUSTER_ID \\*\
*\--db-instance-class db.serverless*\

5610. **Run data validation suite** (row counts by table; hash of key
      business tables).
5611. **Swap connections** (Secrets/Parameter Store → new hostnames).
5612. **Decommission old cluster** after backup (retain snapshot).
5613. **Unfreeze writes**; monitor.

### **RB‑N‑03 --- S3 undelete/restore (versioned buckets)**

**When:** accidental delete/overwrite; NSFW purge rollback.

5614. List object versions:

*aws s3api list-object-versions \--bucket \$S3_ORIG_BUCKET \--prefix
path/to/object.jpg*\

5615. Restore a prior version (copy over latest):

*aws s3api copy-object \\*\
*\--bucket \$S3_ORIG_BUCKET \\*\
*\--key path/to/object.jpg \\*\
*\--copy-source
\${S3_ORIG_BUCKET}/path/to/object.jpg?versionId=\<VERSION\> \\*\
*\--metadata-directive REPLACE*\

5616. Purge CDN for keys:

*aws cloudfront create-invalidation \--distribution-id EABC123 \--paths
\"/path/to/object.jpg\"*\

5617. **If a large batch:** run *ops/dr/s3-restore-list.sh* (iterates
      CSV of keys+versions).

### **RB‑N‑04 --- Typesense loss → full reindex**

**When:** cluster loss/corruption; schema upgrade failure.

5618. **Create new cluster** (ECS/EC2 or managed host) in region.

5619. **Apply schemas** (*ops/typesense/collections.json*).

5620. **Run reindex script** (*ops/dr/typesense_reindex.ts*):

      n.  Pull **hot slices first** (top cities/roles) for fast partial
          recovery.
      o.  Then backfill full corpus.

**Sample reindex skeleton (Node):**

*import { Client } from \'typesense\';*\
*import pg from \'pg\';*\
\
*const ts = new Client({ nodes: \[{ host: process.env.TS_HOST, port:
443, protocol: \'https\' }\], apiKey: process.env.TS_KEY });*\
*const db = new pg.Pool({ connectionString: process.env.DB_URL });*\
\
*async function stream(q: string, f: any, toCollection: string) {*\
*const rows = await db.query(q, f);*\
*const batch = rows.rows.map(normalize);*\
*await ts.collections(toCollection).documents().import(batch, { action:
\'upsert\' });*\
*}*\
\
*(async () =\> {*\
*await stream(\"select \* from search.people_hot(\$1)\", \[/\* city/role
hot list \*/\], \"people\");*\
*await stream(\"select \* from search.people_all()\", \[\],
\"people\");*\
*await stream(\"select \* from search.studios_all()\", \[\],
\"studios\");*\
*await stream(\"select \* from search.work_all()\", \[\], \"work\");*\
*})();*\

### **RB‑N‑05 --- DynamoDB: table restore or global cutover**

**When:** table corruption or mis‑deployment.

- If **Global Tables**: flip app to **secondary replica** (no change
  needed; both active).
- **PITR restore** to new table:

*aws dynamodb restore-table-to-point-in-time \\*\
*\--source-table-name rate_limits \\*\
*\--target-table-name rate_limits_restore\_\$(date +%s) \\*\
*\--use-latest-restorable-time*\

- **Swap** environment variable/alias to new table; archive the old one.

### **RB‑N‑06 --- Stripe webhook outage → replay**

**When:** webhook endpoint down; missed events.

5624. **Identify last processed event time/id** (persisted by your
      processor).
5625. **List events since that point (pseudocode)**:

*\# Using curl or Stripe SDK; pagination by created timestamp*\
*curl -G*
[*https://api.stripe.com/v1/events*](https://api.stripe.com/v1/events)
*\\*\
*-u sk_live\_\...: \\*\
*\--data-urlencode \"created\[gte\]=\<unix_ts\>\" \\*\
*\--data-urlencode \"limit=100\"*\

5626. **Replay** each event into your **idempotent** handler (HTTP POST)
      or **ca